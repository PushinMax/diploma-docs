# RAG-контекст генератор для репозиториев

## Основная задача сервиса

Сервис принимает от GitLab Poller'а `task_id`, по которому можно получить снапшот репозитория (архив/папку со всеми файлами кода на момент анализа), обрабатывает этот снапшот, генерирует качественный RAG-контекст (текстовое представление репозитория, готовое для встраивания в промпт LLM) и сохраняет результат во внешнее хранилище (S3 / MinIO / векторная БД / бакет с json/text файлами).

## Что сервис НЕ делает

* Не скачивает снапшот сам (получает готовый путь / s3_id / url от Poller'а)
* Не делает векторизацию / embedding (это делает отдельный KB сервис или MCP)
* Не хранит контекст сам (только генерирует и отдаёт в S3 / внешнее хранилище)
* Не занимается аутентификацией пользователей (это делает API Gateway)
* Не является фронтендом / чатом / трекером задач

## Основные функции

* Приём задачи от GitLab Poller'а (POST /tasks/process)
* Получение метаданных задачи по task_id (s3_path снапшота, repo_id, commit_sha, etc.)
* Чтение содержимого снапшота из S3
* Фильтрация и предобработка файлов (игнорировать бинарники, .git, node_modules, venv, pycache и т.д.)
* Построение иерархической структуры репозитория
* Генерация текстового представления (разными способами)
* Вызов LLM (через LLM Orchestrator) для улучшения / сжатия / структурирования контекста
* Сохранение результата в S3
* Обновление статуса задачи (через MCP)

## API Endpoints

### POST /tasks/process

Принимает задачу на обработку снапшота репозитория.

**Тело запроса:**
```json
{
  "task_id": "uuid",
  "snapshot_s3_path": "s3://bucket/repo-123/commit-abc/snapshot.zip",
  "repo_id": "uuid or gitlab_project_id",
  "commit_sha": "string",
  "analysis_started_at": "datetime",
  "pooler_id": "uuid"
}
```

**Ответ:**
- 202 Accepted + `{"processing_task_id": "our_internal_id"}`

### GET /tasks/{task_id}/status

Получение статуса задачи.

**Ответ:**
```json
{
  "status": "processing | completed | failed",
  "result_s3_path": "...",
  "error": "..."
}
```

### GET /health
### GET /ready

Эндпоинты для проверки здоровья и готовности сервиса.

### POST /debug/process-sample

Эндпоинт для отладки с маленьким zip-архивом.

## Методы генерации контекста

### Baseline подход
- Дерево файлов
- Для каждого файла: путь + полный код или первые/последние N строк + summary

### Умный подход
- Файлы группируются по директориям / типам (src/, tests/, docs/, config/)
- Для каждого файла вызывается LLM с промптом: «Сделай краткое описание файла: назначение, ключевые классы/функции, связи с другими файлами»
- Собирается общий документ:

```
Repository: my-awesome-project
Commit: abc1234
Structure:
└─ src/
   └─ api/
      └─ main.py → FastAPI приложение, основной роутер, зависимости
      └─ routers/users.py → CRUD для пользователей, JWT auth
Key files summaries:
...
Important patterns:
- Используется Clean Architecture
- Dependency Injection через FastAPI Depends
```

### Максимально сжатый подход
LLM получает дерево + 10–20 самых важных файлов и пишет «единый документ знаний о проекте»

## Технологический стек

* **Framework**: FastAPI (async)
* **Python**: 3.11 / 3.12
* **Конфиг**: pydantic
* **S3**: boto3
* **Архивы**: zipfile + tarfile
* **Очередь задач**: ARQ
* **LLM вызов**: MCP
* **Логирование**: loguru
* **Мониторинг**: prometheus + grafana

## Важные параметры

* **Timeout обработки одного репозитория**: 5–15 минут (гиперпараметр)
* **Размер снапшота**: до 500 МБ (гиперпараметр)
* **Игнорируемые файлы** (hardcoded + конфиг):
  - Изображения и бинарные файлы: .png, .jpg, .pdf, .zip, .exe, .so, .dll
  - Служебные директории: node_modules, vendor, .venv, target, build, dist
  - Кэши: .pyc, pycache, .pytest_cache
* **Ratelimit** (гиперпараметр)
* **Fallback'и** проработаны отдельно